{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Swin Transformers\n\nThis notebook trains a  Vision Transformer on the Butterfly dataset.","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport sys\nfrom tqdm import tqdm\nimport time\nimport copy\n\nimport torch\nimport torchvision\nfrom torchvision import datasets\nfrom torchvision import transforms as T # for simplifying the transforms\nfrom torch import nn, optim\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader, sampler, random_split\nfrom torchvision import models\n\n# remove warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-23T17:26:51.052427Z","iopub.execute_input":"2022-08-23T17:26:51.052859Z","iopub.status.idle":"2022-08-23T17:26:51.067409Z","shell.execute_reply.started":"2022-08-23T17:26:51.052824Z","shell.execute_reply":"2022-08-23T17:26:51.065868Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"## Now, we import timm, torchvision image models\n!pip install timm # kaggle doesnt have it installed by default\nimport timm\nfrom timm.loss import LabelSmoothingCrossEntropy # This is better than normal nn.CrossEntropyLoss","metadata":{"execution":{"iopub.status.busy":"2022-08-23T17:26:52.440131Z","iopub.execute_input":"2022-08-23T17:26:52.440572Z","iopub.status.idle":"2022-08-23T17:27:05.072762Z","shell.execute_reply.started":"2022-08-23T17:26:52.440534Z","shell.execute_reply":"2022-08-23T17:27:05.071450Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Requirement already satisfied: timm in /opt/conda/lib/python3.7/site-packages (0.6.7)\nRequirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.7/site-packages (from timm) (1.11.0+cpu)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from timm) (0.12.0+cpu)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm) (4.1.1)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (9.1.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (1.21.6)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (2.28.1)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->timm) (2022.6.15)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->timm) (2.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->timm) (3.3)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->timm) (1.26.9)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"def get_classes(data_dir):\n    all_data = datasets.ImageFolder(data_dir)\n    return all_data.classes\n\ndef get_data_loaders(data_dir, batch_size, train = False):\n    if train:\n        #train\n        transform = T.Compose([ T.RandomHorizontalFlip(),  T.RandomVerticalFlip(),T.RandomApply(torch.nn.ModuleList([T.ColorJitter()]), p=0.25),\n            T.Resize(256),T.CenterCrop(224),T.ToTensor(),\n            T.Normalize(timm.data.IMAGENET_DEFAULT_MEAN, timm.data.IMAGENET_DEFAULT_STD), # imagenet means\n            T.RandomErasing(p=0.1, value='random')\n        ])\n        train_data = datasets.ImageFolder(os.path.join(data_dir, \"train/\"), transform = transform)\n        train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=4)\n        return train_loader, len(train_data)\n    else:\n        # val/test\n        transform = T.Compose([ # We dont need augmentation for test transforms\n            T.Resize(256),\n            T.CenterCrop(224),\n            T.ToTensor(),\n            T.Normalize(timm.data.IMAGENET_DEFAULT_MEAN, timm.data.IMAGENET_DEFAULT_STD), # imagenet means\n        ])\n        val_data = datasets.ImageFolder(os.path.join(data_dir, \"validation/\"), transform=transform)\n        test_data = datasets.ImageFolder(os.path.join(data_dir, \"test/\"), transform=transform)\n        val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True, num_workers=4)\n        test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=4)\n        return val_loader, test_loader, len(val_data), len(test_data)","metadata":{"execution":{"iopub.status.busy":"2022-08-23T17:34:38.090171Z","iopub.execute_input":"2022-08-23T17:34:38.090729Z","iopub.status.idle":"2022-08-23T17:34:38.102409Z","shell.execute_reply.started":"2022-08-23T17:34:38.090631Z","shell.execute_reply":"2022-08-23T17:34:38.101352Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"dataset_path = \"../input/jute-data/jute_insect_data_split_3/jute_insect_data_split_3\"\n\n(train_loader, train_data_len) = get_data_loaders(dataset_path, 128, train=True)\n(val_loader, test_loader, valid_data_len, test_data_len) = get_data_loaders(dataset_path, 32, train=False)\n\nclasses = get_classes(\"../input/jute-data/jute_insect_data_split_3/jute_insect_data_split_3/train\")\nprint(classes, len(classes))","metadata":{"execution":{"iopub.status.busy":"2022-08-23T17:34:40.818483Z","iopub.execute_input":"2022-08-23T17:34:40.818934Z","iopub.status.idle":"2022-08-23T17:34:41.018092Z","shell.execute_reply.started":"2022-08-23T17:34:40.818897Z","shell.execute_reply":"2022-08-23T17:34:41.016682Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"['Field Cricket', 'Jute Stem Weevil', 'Spilosoma Obliqua', 'Yellow Mite'] 4\n","output_type":"stream"}]},{"cell_type":"code","source":"dataloaders = {\n    \"train\": train_loader,\n    \"val\": val_loader\n}\ndataset_sizes = {\n    \"train\": train_data_len,\n    \"val\": valid_data_len\n}\n\nprint(len(train_loader), len(val_loader), len(test_loader))\n\nprint(train_data_len, valid_data_len, test_data_len)\n\n# now, for the model\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2022-08-23T17:34:48.701510Z","iopub.execute_input":"2022-08-23T17:34:48.702220Z","iopub.status.idle":"2022-08-23T17:34:48.722477Z","shell.execute_reply.started":"2022-08-23T17:34:48.702163Z","shell.execute_reply":"2022-08-23T17:34:48.720569Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"5 7 7\n600 200 200\n","output_type":"stream"},{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"device(type='cpu')"},"metadata":{}}]},{"cell_type":"code","source":"HUB_URL = \"SharanSMenon/swin-transformer-hub:main\"\nMODEL_NAME = \"swin_tiny_patch4_window7_224\"\n# check hubconf for more models.\nmodel = torch.hub.load(HUB_URL, MODEL_NAME, pretrained=True) # load from torch hub","metadata":{"execution":{"iopub.status.busy":"2022-08-23T17:34:56.696028Z","iopub.execute_input":"2022-08-23T17:34:56.696439Z","iopub.status.idle":"2022-08-23T17:34:57.439105Z","shell.execute_reply.started":"2022-08-23T17:34:56.696404Z","shell.execute_reply":"2022-08-23T17:34:57.438095Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/SharanSMenon_swin-transformer-hub_main\n","output_type":"stream"}]},{"cell_type":"code","source":"for param in model.parameters(): #freeze model\n    param.requires_grad = False\n\nn_inputs = model.head.in_features\nmodel.head = nn.Sequential(\n    nn.Linear(n_inputs, 512),\n    nn.ReLU(),\n    nn.Dropout(0.3),\n    nn.Linear(512, len(classes))\n)\nmodel = model.to(device)\nprint(model.head)","metadata":{"execution":{"iopub.status.busy":"2022-08-23T17:34:59.494386Z","iopub.execute_input":"2022-08-23T17:34:59.495487Z","iopub.status.idle":"2022-08-23T17:34:59.510174Z","shell.execute_reply.started":"2022-08-23T17:34:59.495444Z","shell.execute_reply":"2022-08-23T17:34:59.508860Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Sequential(\n  (0): Linear(in_features=768, out_features=512, bias=True)\n  (1): ReLU()\n  (2): Dropout(p=0.3, inplace=False)\n  (3): Linear(in_features=512, out_features=4, bias=True)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"criterion = LabelSmoothingCrossEntropy()\ncriterion = criterion.to(device)\noptimizer = optim.AdamW(model.head.parameters(), lr=0.001)\n\n# lr scheduler\nexp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.97)","metadata":{"execution":{"iopub.status.busy":"2022-08-23T17:35:01.125524Z","iopub.execute_input":"2022-08-23T17:35:01.125932Z","iopub.status.idle":"2022-08-23T17:35:01.133360Z","shell.execute_reply.started":"2022-08-23T17:35:01.125900Z","shell.execute_reply":"2022-08-23T17:35:01.132149Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def train_model(model, criterion, optimizer, scheduler, num_epochs=10):\n    since = time.time()\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    \n    for epoch in range(num_epochs):\n        print(f'Epoch {epoch}/{num_epochs - 1}')\n        print(\"-\"*10)\n        \n        for phase in ['train', 'val']: # We do training and validation phase per epoch\n            if phase == 'train':\n                model.train() # model to training mode\n            else:\n                model.eval() # model to evaluate\n            \n            running_loss = 0.0\n            running_corrects = 0.0\n            \n            for inputs, labels in tqdm(dataloaders[phase]):\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n                \n                optimizer.zero_grad()\n                \n                with torch.set_grad_enabled(phase == 'train'): # no autograd makes validation go faster\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1) # used for accuracy\n                    loss = criterion(outputs, labels)\n                    \n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n                \n            if phase == 'train':\n                scheduler.step() # step at end of epoch\n            \n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc =  running_corrects.double() / dataset_sizes[phase]\n            \n            print(\"{} Loss: {:.4f} Acc: {:.4f}\".format(phase, epoch_loss, epoch_acc))\n            \n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict()) # keep the best validation accuracy model\n        print()\n    time_elapsed = time.time() - since # slight error\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n    print(\"Best Val Acc: {:.4f}\".format(best_acc))\n    \n    model.load_state_dict(best_model_wts)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-08-23T17:35:16.485131Z","iopub.execute_input":"2022-08-23T17:35:16.485583Z","iopub.status.idle":"2022-08-23T17:35:16.500266Z","shell.execute_reply.started":"2022-08-23T17:35:16.485545Z","shell.execute_reply":"2022-08-23T17:35:16.498906Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"model_ft = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs= 15) # now it is a lot faster","metadata":{"execution":{"iopub.status.busy":"2022-08-23T17:35:21.465461Z","iopub.execute_input":"2022-08-23T17:35:21.465924Z","iopub.status.idle":"2022-08-23T18:12:31.833662Z","shell.execute_reply.started":"2022-08-23T17:35:21.465887Z","shell.execute_reply":"2022-08-23T18:12:31.832201Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Epoch 0/14\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5/5 [01:55<00:00, 23.05s/it]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.9952 Acc: 0.7167\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:31<00:00,  4.51s/it]\n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.5797 Acc: 0.9500\n\nEpoch 1/14\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5/5 [01:57<00:00, 23.48s/it]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.5568 Acc: 0.9367\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:31<00:00,  4.53s/it]\n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.4989 Acc: 0.9700\n\nEpoch 2/14\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5/5 [01:56<00:00, 23.24s/it]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.5024 Acc: 0.9683\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:31<00:00,  4.54s/it]\n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.4625 Acc: 0.9800\n\nEpoch 3/14\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5/5 [01:56<00:00, 23.26s/it]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.4612 Acc: 0.9750\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:31<00:00,  4.56s/it]\n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.4254 Acc: 0.9950\n\nEpoch 4/14\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5/5 [01:56<00:00, 23.35s/it]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.4298 Acc: 0.9883\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:31<00:00,  4.56s/it]\n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.4079 Acc: 0.9950\n\nEpoch 5/14\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5/5 [01:56<00:00, 23.29s/it]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.4162 Acc: 0.9900\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:32<00:00,  4.60s/it]\n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.3960 Acc: 0.9950\n\nEpoch 6/14\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5/5 [01:56<00:00, 23.31s/it]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.4044 Acc: 0.9950\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:31<00:00,  4.57s/it]\n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.3875 Acc: 0.9950\n\nEpoch 7/14\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5/5 [01:56<00:00, 23.33s/it]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.3964 Acc: 0.9967\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:32<00:00,  4.61s/it]\n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.3842 Acc: 1.0000\n\nEpoch 8/14\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5/5 [01:55<00:00, 23.19s/it]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.3945 Acc: 0.9933\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:32<00:00,  4.61s/it]\n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.3786 Acc: 1.0000\n\nEpoch 9/14\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5/5 [01:56<00:00, 23.22s/it]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.3917 Acc: 0.9967\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:32<00:00,  4.58s/it]\n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.3767 Acc: 1.0000\n\nEpoch 10/14\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5/5 [01:56<00:00, 23.37s/it]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.3841 Acc: 0.9950\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:32<00:00,  4.66s/it]\n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.3695 Acc: 1.0000\n\nEpoch 11/14\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5/5 [01:59<00:00, 23.96s/it]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.3794 Acc: 0.9967\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:31<00:00,  4.54s/it]\n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.3702 Acc: 1.0000\n\nEpoch 12/14\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5/5 [01:56<00:00, 23.28s/it]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.3796 Acc: 0.9967\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:32<00:00,  4.62s/it]\n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.3698 Acc: 1.0000\n\nEpoch 13/14\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5/5 [01:55<00:00, 23.18s/it]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.3816 Acc: 0.9983\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:32<00:00,  4.60s/it]\n","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.3681 Acc: 1.0000\n\nEpoch 14/14\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5/5 [01:56<00:00, 23.32s/it]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.3803 Acc: 0.9967\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7/7 [00:32<00:00,  4.58s/it]","output_type":"stream"},{"name":"stdout","text":"val Loss: 0.3663 Acc: 1.0000\n\nTraining complete in 37m 10s\nBest Val Acc: 1.0000\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Testing\n\nOk, now we finished training. Lets run the dataset on the test loader and calculate accuracy","metadata":{}},{"cell_type":"code","source":"test_loss = 0.0\nclass_correct = list(0 for i in range(len(classes)))\nclass_total = list(0 for i in range(len(classes)))\nmodel_ft.eval()\n\nfor data, target in tqdm(test_loader):\n    data, target = data.to(device), target.to(device)\n    with torch.no_grad(): # turn off autograd for faster testing\n        output = model_ft(data)\n        loss = criterion(output, target)\n    test_loss = loss.item() * data.size(0)\n    _, pred = torch.max(output, 1)\n    correct_tensor = pred.eq(target.data.view_as(pred))\n    correct = np.squeeze(correct_tensor.cpu().numpy())\n    if len(target) == 32:\n        for i in range(32):\n            label = target.data[i]\n            class_correct[label] += correct[i].item()\n            class_total[label] += 1\n\ntest_loss = test_loss / test_data_len\nprint('Test Loss: {:.4f}'.format(test_loss))\nfor i in range(len(classes)):\n    if class_total[i] > 0:\n        print(\"Test Accuracy of %5s: %2d%% (%2d/%2d)\" % (\n            classes[i], 100*class_correct[i]/class_total[i], np.sum(class_correct[i]), np.sum(class_total[i])\n        ))\n    else:\n        print(\"Test accuracy of %5s: NA\" % (classes[i]))\nprint(\"Test Accuracy of %2d%% (%2d/%2d)\" % (\n            100*np.sum(class_correct)/np.sum(class_total), np.sum(class_correct), np.sum(class_total)\n        ))","metadata":{"execution":{"iopub.status.busy":"2022-08-23T18:14:42.280576Z","iopub.execute_input":"2022-08-23T18:14:42.281077Z","iopub.status.idle":"2022-08-23T18:15:15.212330Z","shell.execute_reply.started":"2022-08-23T18:14:42.281035Z","shell.execute_reply":"2022-08-23T18:15:15.210403Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"100%|██████████| 7/7 [00:32<00:00,  4.70s/it]","output_type":"stream"},{"name":"stdout","text":"Test Loss: 0.0164\nTest Accuracy of Field Cricket: 100% (48/48)\nTest Accuracy of Jute Stem Weevil: 97% (48/49)\nTest Accuracy of Spilosoma Obliqua: 97% (45/46)\nTest Accuracy of Yellow Mite: 100% (49/49)\nTest Accuracy of 98% (190/192)\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# our model earns 93% test accuracy, which is very high. lets save it\nexample = torch.rand(1, 3, 224, 224)\ntraced_script_module = torch.jit.trace(model.cpu(), example)\ntraced_script_module.save(\"Jute.pt\")","metadata":{"execution":{"iopub.status.busy":"2022-08-23T18:15:35.556357Z","iopub.execute_input":"2022-08-23T18:15:35.556885Z","iopub.status.idle":"2022-08-23T18:15:38.355614Z","shell.execute_reply.started":"2022-08-23T18:15:35.556843Z","shell.execute_reply":"2022-08-23T18:15:38.354296Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# That's it for this video, see you next time","metadata":{},"execution_count":null,"outputs":[]}]}